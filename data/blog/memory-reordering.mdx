---
title: "Should I worry about memory reordering or not?"
publishDate: 2023-02-19
summary: "Memory reordering is an important concept to understand in multithreaded programming, but it's not something that developers need to worry about in most cases."
cat: System
gpt: true
---

**TL;DR**

Whether or not you should be concerned about memory reordering depends on the specifics of your programming context and the potential impact of memory reordering on the correctness and performance of your code. In general:

- For single-threaded programs, memory reordering is not a significant concern.
- For user-space multithreaded programs, if you are using a correct library providing synchronization mechanisms, then you don't need to worry about memory reordering.
- However, if your program uses lock-free code, then you should be aware of potential memory reordering issues and use appropriate programming constructs and techniques to prevent them.
- If you are a developer of an operating system, then memory reordering is a significant concern, as the kernel is responsible for managing system resources and ensuring that they are accessed in the correct order.

## Introduction

In the world of software development, memory reordering is a concept that can cause significant concern among developers. It refers to the optimization technique in which a processor reorders instructions to improve performance. However, this reordering can result in inconsistencies and correctness issues that can be difficult to identify and debug. As a result, many developers worry about the potential risks of memory reordering.

But is this concern justified? In this blog post, we will explore why people shouldn't worry too much about memory reordering. We'll explain the mechanics of memory reordering, how modern processors handle this issue, and the built-in constructs in programming languages that prevent memory reordering. We'll also discuss the performance benefits of memory reordering and why it is a necessary technique in many multithreaded applications. By the end of this article, we hope to provide a better understanding of memory reordering and alleviate any worries that developers may have.

## The mechanics of memory reordering

To understand memory reordering, let's first take a look at how instructions are executed on a processor. In a RISC-V processor, for example, the instructions are executed in three stages: fetch, decode, and execute. During the fetch stage, the processor retrieves the instruction from memory. In the decode stage, the processor determines the operation that the instruction represents, and in the execute stage, the instruction is executed.

However, to improve performance, the processor may choose to reorder the instructions. For example, if an instruction in the execute stage is stalled because it's waiting for data, the processor can switch to executing another instruction that doesn't depend on that data. This optimization can improve performance by reducing the number of stalls.

While this optimization can be beneficial, it can also cause issues with consistency and correctness. Consider the following example in C++:

```cpp
int x = 0, y = 0;

void thread_1() {
 x = 1;
 y = 1;
}

void thread_2() {
 while (y != 1) {}
 assert(x == 1);
}
```

This code creates two threads that modify the variables `x` and `y`. Thread 1 sets `x` and `y` to 1, while Thread 2 waits for `y` to be set to 1 and then checks that `x` is also set to 1. However, if the processor reorders the instructions in Thread 1 so that `y` is set to 1 before `x`, then Thread 2 could assert `x` before it's set to 1, resulting in a failure.

In the next part, we'll look at how modern processors handle memory reordering to ensure consistency and correctness.

## Modern Processors and Memory Models

As we mentioned in the previous section, memory reordering can lead to consistency and correctness issues, and modern processors address this problem with memory models. A memory model is like the rulebook for how memory operations interact with each other, similar to how there are rules for how we should behave in social situations (e.g., don't cut in line, don't talk with your mouth full).

Different processors have different memory models with varying levels of strictness. For example, the x86 memory model, used in Intel and AMD processors, is like the strict librarian who follows the rules to the letter. It guarantees that loads and stores are executed in program order and that stores are not reordered with other stores. The ARM memory model, used in ARM processors, is similar but allows certain types of reordering for performance reasons. The RISC-V memory model, on the other hand, is like the fun-loving friend who allows for more flexibility and reordering to improve performance but also requires explicit synchronization instructions to prevent incorrect behavior.

<Callout title="Assembly Code" icon="⚠️">
  It's worth noting that if you're writing programs with assembly
  code, the memory model is the only check for correctness. In this
  case, a weak memory model like the one used in RISC-V may not
  guarantee consistency, so developers should be more cautious and
  aware of the potential issues.
</Callout>

These memory models ensure that the instructions are executed in a consistent and correct order, even when memory reordering is used to improve performance. As a result, most developers don't need to worry too much about memory reordering issues.

While we've seen that memory reordering can cause issues in multithreaded programs, there are ways to prevent and mitigate these issues. One approach is to use memory models that provide ordering constraints on memory operations, such as the Total Store Ordering (TSO) memory model used in x86 processors. Another approach is to use programming language constructs that prevent memory reordering, such as the `volatile` keyword, atomic types and classes, and memory barriers. In the next section, we'll discuss these constructs in more detail and see how they can help prevent memory reordering issues in multithreaded programs.

## Language and Framework Constructs

When it comes to programming languages, there are built-in constructs that can help prevent memory reordering issues. These constructs include `volatile`, atomic types and classes, and memory barriers.

#### Volatile keyword

The `volatile` keyword in C++ ensures that the variable is read and written from/to the main memory instead of being cached in registers or processor caches. This prevents certain types of reordering and can be useful in cases where a variable needs to be shared across threads. Here's an example:

```cpp
volatile bool flag = false;

// Thread 1
while (!flag) {
 // do something
}

// Thread 2
flag = true;
```

In this example, the `volatile` keyword ensures that the write to `flag` in Thread 2 is visible to Thread 1, preventing the loop from running indefinitely.

#### Atomic types and classes

Atomic types and classes provide operations that are guaranteed to be atomic, which means they cannot be interrupted by other threads. This prevents certain types of reordering and can be useful in cases where multiple threads need to access the same variable. Here's an example:

```cpp
#include <atomic>

std::atomic<int> count(0);

// Thread 1
count++;

// Thread 2
count--;
```

In this example, the `std::atomic` class ensures that the increment and decrement operations on `count` are atomic and prevent race conditions that could occur with non-atomic operations.

#### Memory barriers

Memory barriers are explicit instructions that ensure that all memory operations before the barrier are completed before any memory operations after the barrier. This prevents certain types of reordering and can be useful in cases where threads need to synchronize their operations. Here's an example:

```cpp
#include <atomic>

std::atomic<int> counter = 0;

// Thread 1
counter++;
std::atomic_thread_fence(std::memory_order_release);

// Thread 2
std::atomic_thread_fence(std::memory_order_acquire);
counter++;

```

In this example, the `std::atomic_thread_fence` function ensures that the write to `counter` in Thread 1 is visible to Thread 2 before Thread 2 reads the value of `counter`. The `std::memory_order_release` argument for Thread 1 specifies that all prior memory operations (including the write to `counter`) must be completed before the barrier, and the `std::memory_order_acquire` argument for Thread 2 specifies that all subsequent memory operations (including the read of `counter`) must wait until after the barrier. This ensures that the final value of `counter` is 2.

These language constructs can be powerful tools in preventing memory reordering issues, but they can also be tricky to use correctly. It's important to understand how they work and how they can be applied to the specific multithreaded programming scenario.

## When to Use Language Constructs

When programming in a multithreaded environment, there are cases when memory reordering can occur and cause issues with the correctness of the code. In general, when writing code that involves locks, semaphores, or other synchronization mechanisms, the programmer does not need to worry about memory reordering. These constructs are designed to ensure that memory operations occur in the correct order and that the code is thread-safe.

However, when a programmer needs to write lock-free code, they must use the appropriate language constructs to ensure that memory operations occur in the correct order. In C++, for example, the `std::atomic` class provides atomic operations that are guaranteed to be thread-safe and prevent certain types of memory reordering. Similarly, the `volatile` keyword ensures that a variable is read and written from/to the main memory, preventing certain types of reordering. It's important for programmers to understand the use cases for these constructs and to use them appropriately to ensure correct and efficient lock-free code.

In conclusion, while memory reordering can be a concern in multithreaded programming, most programmers do not need to worry about it in their day-to-day work. By using locks, semaphores, and other synchronization mechanisms, most memory reordering issues are prevented. When writing lock-free code, programmers can use language constructs like `std::atomic` and `volatile` to ensure correct and efficient code. By understanding the memory model of your programming language and using the appropriate language constructs, you can ensure that your multithreaded code is correct and efficient.

## Conclusion

In conclusion, memory reordering is an important concept to understand in multithreaded programming, but it's not something that developers need to worry about in most cases. Modern processors and compilers have mechanisms in place to prevent most types of reordering, and programming languages and frameworks provide constructs that help prevent memory reordering issues.

- In single-threaded programming, memory reordering is generally not a concern because there is only one thread accessing and modifying the memory at any given time. With no other threads accessing the same memory, there is no possibility of reordering issues occurring. In addition, modern processors and compilers are designed to optimize single-threaded code by performing various optimizations, such as instruction reordering, without affecting the correctness of the code. As a result, developers do not need to worry about memory reordering when writing single-threaded code.
- When it comes to writing lock-based multithreaded code, developers generally do not need to worry about memory reordering. This is because the synchronization mechanisms used, such as locks, semaphores, and mutexes, are designed to ensure that memory operations occur in the correct order and that the code is thread-safe.

- However, when writing lock-free multithreaded code, developers need to be aware of memory reordering and use the appropriate language constructs to prevent it.
- In addition, operating system developers should worry about memory reordering. Kernel development is a complex and specialized area of programming that involves writing low-level code that interacts directly with the hardware of a computer system. In kernel development, memory reordering can be a significant concern because the kernel is responsible for managing system resources, such as memory, and ensuring that they are accessed in the correct order. Additionally, kernel code often involves synchronization mechanisms that require careful attention to detail to ensure that memory operations occur in the correct order. To prevent memory reordering issues in kernel development, specialized programming techniques and constructs are often used, such as memory barriers, lock-free algorithms, and specialized synchronization primitives. Overall, kernel developers need to be highly aware of memory reordering and its potential effects on system performance and stability, and must use specialized techniques to prevent these issues from occurring.

In general, user-space program developers should not worry about memory reordering unless they are writing lock-free code. If your code involves locks or other synchronization mechanisms, then memory reordering is not a concern. However, if you are writing lock-free code, you should be aware of the memory model of your programming language and use the appropriate language constructs to ensure correct and efficient code.

By understanding the memory model of your programming language and using the appropriate language constructs, you can ensure that your multithreaded code is correct and efficient, without worrying about memory reordering issues.
